{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "# Databasse\n",
    "from metamusic import database\n",
    "import multiprocessing\n",
    "import os\n",
    "import traceback\n",
    "import sys\n",
    "from metamusic import decoder\n",
    "from metamusic import fingerprint\n",
    "from sqlalchemy import func\n",
    "from contextlib import contextmanager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MetaMusic():\n",
    "    \n",
    "    SONG_ID = \"song_id\"\n",
    "    SONG_NAME = 'song_name'\n",
    "    CONFIDENCE = 'confidence'\n",
    "    MATCH_TIME = 'match_time'\n",
    "    OFFSET = 'offset'\n",
    "    OFFSET_SECS = 'offset_seconds'\n",
    "    \n",
    "    \n",
    "    def __init__(self,limit):\n",
    "        database.delete_unfingerprinted_songs()\n",
    "        self.limit =limit\n",
    "        self.get_fingerprinted_songs()\n",
    "    def get_fingerprinted_songs(self):\n",
    "    # get songs previously indexed\n",
    "        self.songs = database.get_songs()\n",
    "        self.songhashes_set = set()  # to know which ones we've computed before\n",
    "        for song in self.songs:\n",
    "            \n",
    "            song_hash = song.file_sha1\n",
    "            print(song_hash,song.song_name)\n",
    "            self.songhashes_set.add(song_hash.decode())\n",
    "        print(self.songhashes_set)\n",
    "            \n",
    "  \n",
    "    def fingerprint_directory(self, path, extensions, nprocesses=None):\n",
    "\n",
    "        # Try to use the maximum amount of processes if not given.\n",
    "        try:\n",
    "            nprocesses = nprocesses or multiprocessing.cpu_count()\n",
    "\n",
    "        except NotImplementedError:\n",
    "            nprocesses = 1\n",
    "        else:\n",
    "            nprocesses = 1 if nprocesses <= 0 else nprocesses\n",
    "\n",
    "        pool = multiprocessing.Pool(nprocesses)\n",
    "        \n",
    "        filenames_to_fingerprint = []\n",
    "        mp3_file = []\n",
    "        temp_hash = []\n",
    "\n",
    "        for dirpath, dirnames, files in os.walk(path):\n",
    "            for i in files:\n",
    "                if i.endswith('.mp3'):\n",
    "                    mp3_file.append(os.path.join(dirpath, i))\n",
    "        print(mp3_file)\n",
    "        hashes_sha1 = pool.map(decoder.unique_hash, mp3_file)\n",
    "        print(hashes_sha1)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        # don't refingerprint already fingerprinted files\n",
    "        for n, i in enumerate(hashes_sha1):\n",
    "\n",
    "            if i in self.songhashes_set:\n",
    "                print(\"%s already fingerprinted, continuing...\" % i)\n",
    "                temp_hash.append(i)\n",
    "                continue\n",
    "\n",
    "            filenames_to_fingerprint.append(mp3_file[n])\n",
    "        for i in temp_hash:\n",
    "            hashes_sha1.remove(i)\n",
    "        print('added')\n",
    "        mp3_file = None\n",
    "        temp_hash = None\n",
    "\n",
    "        # Prepare _fingerprint_worker input\n",
    "        worker_input = zip(filenames_to_fingerprint, [\n",
    "                           self.limit] * len(filenames_to_fingerprint), range(len(hashes_sha1)))\n",
    "        pool = multiprocessing.Pool(nprocesses)\n",
    "\n",
    "        # Send off our tasks\n",
    "        iterator = pool.imap_unordered(_fingerprint_worker, worker_input)\n",
    "   \n",
    "        # Loop till we have all of them\n",
    "        while True:\n",
    "            try:\n",
    "                song_name, hashes, num = iterator.next()\n",
    "            except multiprocessing.TimeoutError:\n",
    "                continue\n",
    "            except StopIteration:\n",
    "                break\n",
    "            except:\n",
    "                print(\"Failed fingerprinting\")\n",
    "                # Print traceback because we can't reraise it here\n",
    "                traceback.print_exc(file=sys.stdout)\n",
    "            else:\n",
    "                database.insert_song(file_hash=hashes_sha1[num],\n",
    "                                     song_name=song_name)\n",
    "                database.set_fingerprinted_flag()\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    \n",
    "\n",
    "\n",
    "def _fingerprint_worker(filename):\n",
    "    # Pool.imap sends arguments as tuples so we have to unpack\n",
    "    # them ourself.\n",
    "    try:\n",
    "        filename, limit, num = filename\n",
    "        song_name = None\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    songname, extension = os.path.splitext(os.path.basename(filename))\n",
    "    song_name = song_name or songname\n",
    "    channels, Fs = decoder.read(filename, limit)\n",
    "    result = set()\n",
    "    channel_amount = len(channels)\n",
    "\n",
    "    for channeln, channel in enumerate(channels):\n",
    "        # TODO: Remove prints or change them into optional logging.\n",
    "        print(\"Fingerprinting channel %d/%d for %s\" % (channeln + 1,\n",
    "                                                       channel_amount,\n",
    "                                                       filename))\n",
    "        hashes = fingerprint.fingerprint(channel, Fs=Fs)\n",
    "        print(\"Finished channel %d/%d for %s\" % (channeln + 1, channel_amount,\n",
    "                                                 filename))\n",
    "        result = set(hashes)\n",
    "\n",
    "    return song_name, result, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'33B9B8622EF68CBCC6B9775A56A141673EB265C4' Adhuro Prem\n",
      "b'1211BA4E4D6A74C99EAD91E31E055E975CCBD942' sfd\n",
      "b'784C30646AC349BA162159E49B6170FCDD698BF0' The Nights\n",
      "b'13F1B4866A723FD0D487691B1AB50D1FAE62D5F9' Waiting for Love\n",
      "{'33B9B8622EF68CBCC6B9775A56A141673EB265C4', '1211BA4E4D6A74C99EAD91E31E055E975CCBD942', '784C30646AC349BA162159E49B6170FCDD698BF0', '13F1B4866A723FD0D487691B1AB50D1FAE62D5F9'}\n",
      "['/home/unique/Documents/Meta-Music/mp3/Waiting for Love.mp3', '/home/unique/Documents/Meta-Music/mp3/The Nights.mp3', '/home/unique/Documents/Meta-Music/mp3/aaa.mp3', '/home/unique/Documents/Meta-Music/mp3/Adhuro Prem.mp3']\n",
      "['13F1B4866A723FD0D487691B1AB50D1FAE62D5F9', '784C30646AC349BA162159E49B6170FCDD698BF0', '1211BA4E4D6A74C99EAD91E31E055E975CCBD942', '33B9B8622EF68CBCC6B9775A56A141673EB265C4']\n",
      "13F1B4866A723FD0D487691B1AB50D1FAE62D5F9 already fingerprinted, continuing...\n",
      "784C30646AC349BA162159E49B6170FCDD698BF0 already fingerprinted, continuing...\n",
      "1211BA4E4D6A74C99EAD91E31E055E975CCBD942 already fingerprinted, continuing...\n",
      "33B9B8622EF68CBCC6B9775A56A141673EB265C4 already fingerprinted, continuing...\n",
      "added\n"
     ]
    }
   ],
   "source": [
    "m=MetaMusic(10)\n",
    "m.fingerprint_directory('/home/unique/Documents/Meta-Music/mp3',['.mp3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IDX_FREQ_I = 0\n",
    "IDX_TIME_J = 1\n",
    "\n",
    "######################################################################\n",
    "# Sampling rate, related to the Nyquist conditions, which affects\n",
    "# the range frequencies we can detect.\n",
    "DEFAULT_FS = 44100\n",
    "\n",
    "######################################################################\n",
    "# Size of the FFT window, affects frequency granularity\n",
    "DEFAULT_WINDOW_SIZE = 4096\n",
    "\n",
    "######################################################################\n",
    "# Ratio by which each sequential window overlaps the last and the\n",
    "# next window. Higher overlap will allow a higher granularity of offset\n",
    "# matching, but potentially more fingerprints.\n",
    "DEFAULT_OVERLAP_RATIO = 0.5\n",
    "\n",
    "######################################################################\n",
    "# Degree to which a fingerprint can be paired with its neighbors --\n",
    "# higher will cause more fingerprints, but potentially better accuracy.\n",
    "DEFAULT_FAN_VALUE = 15\n",
    "\n",
    "######################################################################\n",
    "# Minimum amplitude in spectrogram in order to be considered a peak.\n",
    "# This can be raised to reduce number of fingerprints, but can negatively\n",
    "# affect accuracy.\n",
    "DEFAULT_AMP_MIN = 10\n",
    "\n",
    "######################################################################\n",
    "# Number of cells around an amplitude peak in the spectrogram in order\n",
    "# for MetaMusic to consider it a spectral peak. Higher values mean less\n",
    "# fingerprints and faster matching, but can potentially affect accuracy.\n",
    "PEAK_NEIGHBORHOOD_SIZE = 20\n",
    "\n",
    "######################################################################\n",
    "# Thresholds on how close or far fingerprints can be in time in order\n",
    "# to be paired as a fingerprint. If your max is too low, higher values of\n",
    "# DEFAULT_FAN_VALUE may not perform as expected.\n",
    "MIN_HASH_TIME_DELTA = 0\n",
    "MAX_HASH_TIME_DELTA = 200\n",
    "\n",
    "######################################################################\n",
    "# If True, will sort peaks temporally for fingerprinting;\n",
    "# not sorting will cut down number of fingerprints, but potentially\n",
    "# affect performance.\n",
    "PEAK_SORT = True\n",
    "\n",
    "######################################################################\n",
    "# Number of bits to throw away from the front of the SHA1 hash in the\n",
    "# fingerprint calculation. The more you throw away, the less storage, but\n",
    "# potentially higher collisions and misclassifications when identifying songs.\n",
    "FINGERPRINT_REDUCTION = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "from scipy.ndimage.morphology import (generate_binary_structure,\n",
    "                                      iterate_structure, binary_erosion)\n",
    "import hashlib\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct = generate_binary_structure(2, 1)\n",
    "neighborhood = iterate_structure(struct, PEAK_NEIGHBORHOOD_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=AudioSegment.from_file('/media/unique/extra/mu/A thousand times.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12574703.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.frame_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12574703.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.frame_rate*261.9729791666667\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "960000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=a[:10000]\n",
    "len(np.fromstring(a._data,np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
